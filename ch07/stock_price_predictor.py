import os
import glob
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score


def load_processed_data(data_dir="processed_data"):
    try:
        train_files = glob.glob(f"{data_dir}/X_train_*.csv")
        test_files = glob.glob(f"{data_dir}/X_test_*.csv")
        y_train_files = glob.glob(f"{data_dir}/y_train_*.csv")
        y_test_files = glob.glob(f"{data_dir}/y_test_*.csv")

        if not train_files or not test_files:
            print(f"'{data_dir}' í´ë”ì—ì„œ ì „ì²˜ë¦¬ëœ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None, None, None, None

        latest_train = max(train_files, key=os.path.getctime)
        latest_test = max(test_files, key=os.path.getctime)
        latest_y_train = max(y_train_files, key=os.path.getctime)
        latest_y_test = max(y_test_files, key=os.path.getctime)

        print("=== ë°ì´í„° ë¡œë“œ ===")
        print(f"í›ˆë ¨ íŠ¹ì„± íŒŒì¼: {os.path.basename(latest_train)}")
        print(f"í…ŒìŠ¤íŠ¸ íŠ¹ì„± íŒŒì¼: {os.path.basename(latest_test)}")
        print(f"í›ˆë ¨ íƒ€ê²Ÿ íŒŒì¼: {os.path.basename(latest_y_train)}")
        print(f"í…ŒìŠ¤íŠ¸ íƒ€ê²Ÿ íŒŒì¼: {os.path.basename(latest_y_test)}")

        X_train = pd.read_csv(latest_train, index_col=0)
        X_test = pd.read_csv(latest_test, index_col=0)
        y_train = pd.read_csv(latest_y_train, index_col=0).iloc[:, 0]
        y_test = pd.read_csv(latest_y_test, index_col=0).iloc[:, 0]

        print(f"í›ˆë ¨ ë°ì´í„°: {X_train.shape[0]}ê°œ ìƒ˜í”Œ, {X_train.shape[1]}ê°œ íŠ¹ì„±")
        print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape[0]}ê°œ ìƒ˜í”Œ, {X_test.shape[1]}ê°œ íŠ¹ì„±")

        return X_train, X_test, y_train, y_test

    except Exception as error:
        print(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {error}")
        return None, None, None, None


def clean_data(X_train, X_test, y_train, y_test):
    print("\n=== ë°ì´í„° ì •ë¦¬ ===")
    print("ë¬´í•œëŒ€ ê°’ í™•ì¸:")
    for col in X_train.columns:
        inf_count = np.isinf(X_train[col]).sum()
        if inf_count > 0:
            print(f"  {col}: {inf_count}ê°œ")

    X_train = X_train.replace([np.inf, -np.inf], np.nan)
    X_test = X_test.replace([np.inf, -np.inf], np.nan)

    for col in X_train.columns:
        if X_train[col].isnull().sum() > 0:
            median_val = X_train[col].median()
            X_train[col].fillna(median_val, inplace=True)
            X_test[col].fillna(median_val, inplace=True)

    print("ì´ìƒì¹˜ ì œê±°:")
    for col in X_train.columns:
        mean_val = X_train[col].mean()
        std_val = X_train[col].std()
        lower_bound = mean_val - 3 * std_val
        upper_bound = mean_val + 3 * std_val
        outlier_count = ((X_train[col] < lower_bound) | (X_train[col] > upper_bound)).sum()
        if outlier_count > 0:
            print(f"  {col}: {outlier_count}ê°œ ì´ìƒì¹˜")
            median_val = X_train[col].median()
            X_train.loc[X_train[col] < lower_bound, col] = median_val
            X_train.loc[X_train[col] > upper_bound, col] = median_val

    print("ë°ì´í„° ì •ë¦¬ ì™„ë£Œ!")
    return X_train, X_test, y_train, y_test


def train_linear_regression_model(X_train, y_train):
    print("\n=== ì„ í˜• íšŒê·€ ëª¨ë¸ í›ˆë ¨ ===")
    model = LinearRegression()
    model.fit(X_train, y_train)
    print("ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
    print(f"ì ˆí¸ (Intercept): {model.intercept_:.2f}")
    feature_importance = pd.DataFrame({
        'íŠ¹ì„±': X_train.columns,
        'ê³„ìˆ˜': model.coef_
    }).sort_values('ê³„ìˆ˜', key=abs, ascending=False)
    print("\n=== íŠ¹ì„± ì¤‘ìš”ë„ (ì ˆëŒ“ê°’ ê¸°ì¤€) ===")
    for i, (_, row) in enumerate(feature_importance.head(10).iterrows(), 1):
        print(f"{i:2d}. {row['íŠ¹ì„±']:<20} : {row['ê³„ìˆ˜']:>10.2f}")
    return model, feature_importance


def evaluate_model(model, X_test, y_test):
    print("\n=== ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ===")
    y_pred = model.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
    print(f"í‰ê·  ì œê³± ì˜¤ì°¨ (MSE): {mse:,.2f}")
    print(f"í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨ (RMSE): {rmse:,.2f}")
    print(f"í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (MAE): {mae:,.2f}")
    print(f"ê²°ì • ê³„ìˆ˜ (RÂ²): {r2:.4f}")
    print(f"í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ ë¹„ìœ¨ (MAPE): {mape:.2f}%")
    return y_pred, {'mse': mse, 'rmse': rmse, 'mae': mae, 'r2': r2, 'mape': mape}


def plot_predictions(y_test, y_pred, save_dir="results"):
    print("\n=== ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™” ===")
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)

    # font_test.py ë°©ì‹ìœ¼ë¡œ í•œê¸€ í°íŠ¸ ì„¤ì • (ì „ì—­ ì„¤ì •)
    try:
        # font_test.pyì—ì„œ ì‚¬ìš©í•œ ë°©ì‹ê³¼ ë™ì¼í•˜ê²Œ ì„¤ì •
        plt.rcParams['font.family'] = 'Malgun Gothic'
        plt.rcParams['axes.unicode_minus'] = False
        print("âœ“ í•œê¸€ í°íŠ¸ ì„¤ì • ì™„ë£Œ: Malgun Gothic (font_test.py ë°©ì‹)")
    except Exception as e:
        print(f"âš ï¸ í°íŠ¸ ì„¤ì • ì‹¤íŒ¨: {e}")
        # ëŒ€ì²´ í°íŠ¸ ì‹œë„
        try:
            plt.rcParams['font.family'] = 'Batang'
            plt.rcParams['axes.unicode_minus'] = False
            print("âœ“ ëŒ€ì²´ í°íŠ¸ ì„¤ì •: Batang")
        except:
            print("âš ï¸ í°íŠ¸ ì„¤ì • ì‹¤íŒ¨")
    
    plt.rcParams['font.size'] = 10
    import warnings
    warnings.filterwarnings('ignore', category=UserWarning)
    warnings.filterwarnings('ignore', category=FutureWarning)

    # font_test.pyì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ê·¸ë˜í”„ ìƒì„±
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))

    axes[0, 0].scatter(y_test, y_pred, alpha=0.6, color='blue')
    axes[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
    axes[0, 0].set_xlabel('ì‹¤ì œ ì£¼ê°€')
    axes[0, 0].set_ylabel('ì˜ˆì¸¡ ì£¼ê°€')
    axes[0, 0].set_title('ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’')
    axes[0, 0].grid(True, alpha=0.3)

    axes[0, 1].plot(y_test.index, y_test.values, label='ì‹¤ì œ', color='blue', alpha=0.7)
    axes[0, 1].plot(y_test.index, y_pred, label='ì˜ˆì¸¡', color='red', alpha=0.7)
    axes[0, 1].set_xlabel('ë‚ ì§œ')
    axes[0, 1].set_ylabel('ì£¼ê°€')
    axes[0, 1].set_title('ì‹œê°„ì— ë”°ë¥¸ ì£¼ê°€ ì˜ˆì¸¡')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)

    residuals = y_test - y_pred
    axes[1, 0].hist(residuals, bins=30, alpha=0.7, color='green', edgecolor='black')
    axes[1, 0].set_xlabel('ì˜ˆì¸¡ ì˜¤ì°¨')
    axes[1, 0].set_ylabel('ë¹ˆë„ìˆ˜')
    axes[1, 0].set_title('ì˜ˆì¸¡ ì˜¤ì°¨ ë¶„í¬')
    axes[1, 0].grid(True, alpha=0.3)

    axes[1, 1].plot(y_test.index, residuals, color='orange', alpha=0.7)
    axes[1, 1].axhline(y=0, color='red', linestyle='--', alpha=0.5)
    axes[1, 1].set_xlabel('ë‚ ì§œ')
    axes[1, 1].set_ylabel('ì˜ˆì¸¡ ì˜¤ì°¨')
    axes[1, 1].set_title('ì‹œê°„ì— ë”°ë¥¸ ì˜ˆì¸¡ ì˜¤ì°¨')
    axes[1, 1].grid(True, alpha=0.3)

    plt.tight_layout()
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    plot_filename = f"{save_dir}/prediction_results_{timestamp}.png"
    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')
    print(f"ê·¸ë˜í”„ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {plot_filename}")
    plt.show()


def save_model_results(model, feature_importance, metrics, save_dir="results"):
    print("\n=== ê²°ê³¼ ì €ì¥ ===")
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
    
    # models í´ë” ìƒì„±
    models_dir = "models"
    if not os.path.exists(models_dir):
        os.makedirs(models_dir)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # íŠ¹ì„± ì¤‘ìš”ë„ì™€ ì„±ëŠ¥ ì§€í‘œ ì €ì¥
    feature_importance.to_csv(f"{save_dir}/feature_importance_{timestamp}.csv", index=False, encoding='utf-8-sig')
    metrics_df = pd.DataFrame([metrics])
    metrics_df.to_csv(f"{save_dir}/model_performance_{timestamp}.csv", index=False, encoding='utf-8-sig')
    
    # í›ˆë ¨ëœ ëª¨ë¸ ì €ì¥ (pickle í˜•ì‹)
    import pickle
    model_filename = f"{models_dir}/stock_price_model_{timestamp}.pkl"
    with open(model_filename, 'wb') as f:
        pickle.dump(model, f)
    
    print(f"íŠ¹ì„± ì¤‘ìš”ë„: {save_dir}/feature_importance_{timestamp}.csv")
    print(f"ì„±ëŠ¥ ì§€í‘œ: {save_dir}/model_performance_{timestamp}.csv")
    print(f"í›ˆë ¨ëœ ëª¨ë¸: {model_filename}")


def predict_next_day(model, X_test, y_test, feature_names):
    print("\n=== ë‹¤ìŒë‚  ì£¼ê°€ ì˜ˆì¸¡ ===")
    latest_data = X_test.iloc[-1:].values
    next_day_prediction = model.predict(latest_data)[0]
    print(f"ê°€ì¥ ìµœê·¼ ë°ì´í„° ê¸°ì¤€ì¼: {X_test.index[-1]}")
    print(f"ì˜ˆì¸¡ëœ ë‹¤ìŒë‚  ì£¼ê°€: {next_day_prediction:,.0f}ì›")
    confidence = "ë†’ìŒ" if model.score(X_test, y_test) > 0.7 else "ë³´í†µ" if model.score(X_test, y_test) > 0.5 else "ë‚®ìŒ"
    print(f"ì˜ˆì¸¡ ì‹ ë¢°ë„: {confidence}")
    return next_day_prediction


def main():
    print("=== ì‚¼ì„±ì „ì ì£¼ê°€ ì˜ˆì¸¡ ëª¨ë¸ (ì„ í˜• íšŒê·€) ===")
    X_train, X_test, y_train, y_test = load_processed_data()
    if X_train is None:
        print("ë°ì´í„° ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¨¼ì € data_preprocessing.pyë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return
    X_train, X_test, y_train, y_test = clean_data(X_train, X_test, y_train, y_test)
    model, feature_importance = train_linear_regression_model(X_train, y_train)
    y_pred, metrics = evaluate_model(model, X_test, y_test)
    plot_predictions(y_test, y_pred)
    save_model_results(model, feature_importance, metrics)
    predict_next_day(model, X_test, y_test, X_test.columns)
    print("\n=== ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ ===")
    print("ğŸ“Š ì£¼ìš” ê²°ê³¼:")
    print(f"  - ëª¨ë¸ ì •í™•ë„ (RÂ²): {metrics['r2']:.4f}")
    print(f"  - í‰ê·  ì˜ˆì¸¡ ì˜¤ì°¨: {metrics['mae']:,.0f}ì›")
    print(f"  - ì˜ˆì¸¡ ì˜¤ì°¨ ë¹„ìœ¨: {metrics['mape']:.2f}%")

if __name__ == "__main__":
    main()
