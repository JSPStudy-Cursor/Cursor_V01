import torch
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import re
import logging
from typing import Optional, Dict, Any
import warnings
warnings.filterwarnings('ignore')

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AdvancedNewsSummarizer:
    """
    ì‚¬ì „ í•™ìŠµëœ T5/BART ëª¨ë¸ì„ ì‚¬ìš©í•œ ê³ ê¸‰ ë‰´ìŠ¤ ìš”ì•½ê¸°
    """
    
    def __init__(self, model_name: str = "paust/pko-t5-large"):
        """
        ëª¨ë¸ ì´ˆê¸°í™”
        Args:
            model_name: ì‚¬ìš©í•  ëª¨ë¸ëª… (ê¸°ë³¸ê°’: í•œêµ­ì–´ T5 ëª¨ë¸)
        """
        self.model_name = model_name
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        try:
            logger.info(f"ëª¨ë¸ ë¡œë”© ì¤‘: {model_name}")
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
            self.model.to(self.device)
            logger.info(f"ëª¨ë¸ ë¡œë”© ì™„ë£Œ (ë””ë°”ì´ìŠ¤: {self.device})")
        except Exception as e:
            logger.error(f"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            raise
    
    def preprocess_text(self, text: str) -> str:
        """
        í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        - HTML íƒœê·¸ ì œê±°
        - íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬
        - ê³µë°± ì •ë¦¬
        """
        try:
            # HTML íƒœê·¸ ì œê±°
            text = re.sub(r'<[^>]+>', '', text)
            # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
            text = re.sub(r'\s+', ' ', text)
            # ì•ë’¤ ê³µë°± ì œê±°
            text = text.strip()
            return text
        except Exception as e:
            logger.error(f"í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return text
    
    def split_long_text(self, text: str, max_length: int = 1024) -> list:
        """
        ê¸´ í…ìŠ¤íŠ¸ë¥¼ ëª¨ë¸ì´ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í¬ê¸°ë¡œ ë¶„í• 
        """
        try:
            if len(text) <= max_length:
                return [text]
            
            # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
            sentences = re.split(r'[.!?]', text)
            chunks = []
            current_chunk = ""
            
            for sentence in sentences:
                sentence = sentence.strip()
                if not sentence:
                    continue
                
                # í˜„ì¬ ì²­í¬ì— ë¬¸ì¥ ì¶”ê°€ ì‹œ ê¸¸ì´ í™•ì¸
                if len(current_chunk + sentence) < max_length:
                    current_chunk += sentence + ". "
                else:
                    if current_chunk:
                        chunks.append(current_chunk.strip())
                    current_chunk = sentence + ". "
            
            # ë§ˆì§€ë§‰ ì²­í¬ ì¶”ê°€
            if current_chunk:
                chunks.append(current_chunk.strip())
            
            return chunks if chunks else [text]
            
        except Exception as e:
            logger.error(f"í…ìŠ¤íŠ¸ ë¶„í•  ì¤‘ ì˜¤ë¥˜: {e}")
            return [text]
    
    def summarize_text(self, text: str, max_length: int = 150, min_length: int = 50) -> str:
        """
        í…ìŠ¤íŠ¸ ìš”ì•½ ìƒì„±
        Args:
            text: ìš”ì•½í•  í…ìŠ¤íŠ¸
            max_length: ìµœëŒ€ ìš”ì•½ ê¸¸ì´
            min_length: ìµœì†Œ ìš”ì•½ ê¸¸ì´
        Returns:
            ìš”ì•½ëœ í…ìŠ¤íŠ¸
        """
        try:
            if not text or len(text.strip()) == 0:
                return "ìš”ì•½í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."
            
            # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
            cleaned_text = self.preprocess_text(text)
            
            # ê¸´ í…ìŠ¤íŠ¸ ë¶„í• 
            text_chunks = self.split_long_text(cleaned_text)
            
            summaries = []
            
            for chunk in text_chunks:
                # í† í¬ë‚˜ì´ì €ë¡œ ì¸ì½”ë”©
                inputs = self.tokenizer(
                    chunk, 
                    max_length=1024, 
                    truncation=True, 
                    padding=True, 
                    return_tensors="pt"
                ).to(self.device)
                
                # ìš”ì•½ ìƒì„±
                with torch.no_grad():
                    summary_ids = self.model.generate(
                        inputs["input_ids"],
                        max_length=max_length,
                        min_length=min_length,
                        num_beams=4,
                        length_penalty=2.0,
                        early_stopping=True,
                        no_repeat_ngram_size=3
                    )
                
                # ë””ì½”ë”©
                summary = self.tokenizer.decode(summary_ids[0], skip_special_tokens=True)
                summaries.append(summary)
            
            # ì—¬ëŸ¬ ì²­í¬ì˜ ìš”ì•½ì„ ê²°í•©
            final_summary = " ".join(summaries)
            
            return final_summary.strip()
            
        except Exception as e:
            logger.error(f"ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return f"ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
    
    def get_summary_info(self, original_text: str, summary: str) -> Dict[str, Any]:
        """
        ìš”ì•½ ì •ë³´ ë°˜í™˜ (ì›ë³¸ ê¸¸ì´, ìš”ì•½ ê¸¸ì´, ì••ì¶•ë¥  ë“±)
        """
        try:
            original_length = len(original_text)
            summary_length = len(summary)
            compression_ratio = (1 - summary_length / original_length) * 100 if original_length > 0 else 0
            
            return {
                "original_length": original_length,
                "summary_length": summary_length,
                "compression_ratio": round(compression_ratio, 2),
                "model_name": self.model_name
            }
        except Exception as e:
            logger.error(f"ìš”ì•½ ì •ë³´ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            return {}
    
    def interactive_summarize(self):
        """
        ëŒ€í™”í˜• ìš”ì•½ ì¸í„°í˜ì´ìŠ¤
        """
        print("=== ë‰´ìŠ¤ ê¸°ì‚¬ ìš”ì•½ í”„ë¡œê·¸ë¨ ===")
        print("ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        print()
        
        while True:
            try:
                # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
                print("ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”:")
                user_input = input("> ")
                
                if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
                    print("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
                
                if not user_input.strip():
                    print("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    continue
                
                print("\nìš”ì•½ ìƒì„± ì¤‘...")
                
                # ìš”ì•½ ìƒì„±
                summary = self.summarize_text(user_input)
                
                # ìš”ì•½ ì •ë³´ ê³„ì‚°
                info = self.get_summary_info(user_input, summary)
                
                # ê²°ê³¼ ì¶œë ¥
                print("\n" + "="*50)
                print("ğŸ“° ìš”ì•½ ê²°ê³¼")
                print("="*50)
                print(f"ğŸ“ ìš”ì•½: {summary}")
                print(f"ğŸ“Š ì›ë³¸ ê¸¸ì´: {info.get('original_length', 0)}ì")
                print(f"ğŸ“Š ìš”ì•½ ê¸¸ì´: {info.get('summary_length', 0)}ì")
                print(f"ğŸ“Š ì••ì¶•ë¥ : {info.get('compression_ratio', 0)}%")
                print(f"ğŸ¤– ì‚¬ìš© ëª¨ë¸: {info.get('model_name', 'Unknown')}")
                print("="*50)
                print()
                
            except KeyboardInterrupt:
                print("\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            except Exception as e:
                logger.error(f"ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤ ì˜¤ë¥˜: {e}")
                print(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


def main():
    """
    ë©”ì¸ í•¨ìˆ˜ - ì‚¬ìš© ì˜ˆì‹œ
    """
    try:
        # ëª¨ë¸ ì´ˆê¸°í™” (ì²« ì‹¤í–‰ ì‹œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)
        print("ëª¨ë¸ì„ ë¡œë”©í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
        summarizer = AdvancedNewsSummarizer()
        
        # ì˜ˆì‹œ ë‰´ìŠ¤ í…ìŠ¤íŠ¸
        sample_news = """
        ì„œìš¸ì‹œëŠ” ì˜¤ëŠ˜ ìƒˆë¡œìš´ í™˜ê²½ ì •ì±…ì„ ë°œí‘œí–ˆìŠµë‹ˆë‹¤. 
        ì´ë²ˆ ì •ì±…ì€ íƒ„ì†Œ ë°°ì¶œëŸ‰ì„ 2030ë…„ê¹Œì§€ 40% ê°ì¶•í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.
        ì‹œë¯¼ë“¤ì˜ ì°¸ì—¬ê°€ ì¤‘ìš”í•œ ì´ë²ˆ ì •ì±…ì€ ë‹¤ì–‘í•œ ì¸ì„¼í‹°ë¸Œë¥¼ ì œê³µí•  ì˜ˆì •ì…ë‹ˆë‹¤.
        ì „ë¬¸ê°€ë“¤ì€ ì´ë²ˆ ì •ì±…ì´ ì „êµ­ì ìœ¼ë¡œ í™•ì‚°ë  ê°€ëŠ¥ì„±ì´ ë†’ë‹¤ê³  í‰ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤.
        """
        
        print("=== ì˜ˆì‹œ ìš”ì•½ ===")
        print(f"ì›ë³¸: {sample_news.strip()}")
        print()
        
        summary = summarizer.summarize_text(sample_news)
        print(f"ìš”ì•½: {summary}")
        print()
        
        # ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤ ì‹œì‘
        summarizer.interactive_summarize()
        
    except Exception as e:
        logger.error(f"í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        print(f"í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


if __name__ == "__main__":
    main() 