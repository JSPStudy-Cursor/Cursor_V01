import torch
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import re
import logging
from typing import Optional, Dict, Any
import warnings
warnings.filterwarnings('ignore')

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SimpleNewsSummarizer:
    """
    ì‚¬ìš©ì ì¹œí™”ì ì¸ ê°„ë‹¨í•œ ë‰´ìŠ¤ ìš”ì•½ê¸°
    """
    
    def __init__(self, model_name: str = "paust/pko-t5-large"):
        """
        ëª¨ë¸ ì´ˆê¸°í™”
        """
        self.model_name = model_name
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = None
        self.tokenizer = None
        
    def load_model(self):
        """
        ëª¨ë¸ ë¡œë”© (í•„ìš”í•  ë•Œë§Œ ë¡œë”©)
        """
        if self.model is None:
            try:
                logger.info(f"ëª¨ë¸ ë¡œë”© ì¤‘: {self.model_name}")
                self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
                self.model = AutoModelForSeq2SeqLM.from_pretrained(self.model_name)
                self.model.to(self.device)
                logger.info(f"ëª¨ë¸ ë¡œë”© ì™„ë£Œ (ë””ë°”ì´ìŠ¤: {self.device})")
            except Exception as e:
                logger.error(f"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
                raise
    
    def clean_text(self, text: str) -> str:
        """
        í…ìŠ¤íŠ¸ ì •ë¦¬
        """
        try:
            # HTML íƒœê·¸ ì œê±°
            text = re.sub(r'<[^>]+>', '', text)
            # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
            text = re.sub(r'\s+', ' ', text)
            # ì•ë’¤ ê³µë°± ì œê±°
            return text.strip()
        except Exception as e:
            logger.error(f"í…ìŠ¤íŠ¸ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return text
    
    def summarize(self, text: str, max_length: int = 100) -> str:
        """
        í…ìŠ¤íŠ¸ ìš”ì•½
        """
        try:
            if not text or len(text.strip()) == 0:
                return "ìš”ì•½í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."
            
            # ëª¨ë¸ ë¡œë”©
            self.load_model()
            
            # í…ìŠ¤íŠ¸ ì •ë¦¬
            cleaned_text = self.clean_text(text)
            
            # í† í¬ë‚˜ì´ì €ë¡œ ì¸ì½”ë”©
            inputs = self.tokenizer(
                cleaned_text, 
                max_length=1024, 
                truncation=True, 
                padding=True, 
                return_tensors="pt"
            ).to(self.device)
            
            # ìš”ì•½ ìƒì„±
            with torch.no_grad():
                summary_ids = self.model.generate(
                    inputs["input_ids"],
                    max_length=max_length,
                    min_length=30,
                    num_beams=4,
                    length_penalty=2.0,
                    early_stopping=True,
                    no_repeat_ngram_size=3
                )
            
            # ë””ì½”ë”©
            summary = self.tokenizer.decode(summary_ids[0], skip_special_tokens=True)
            
            return summary.strip()
            
        except Exception as e:
            logger.error(f"ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return f"ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
    
    def get_summary_stats(self, original: str, summary: str) -> Dict[str, Any]:
        """
        ìš”ì•½ í†µê³„ ì •ë³´
        """
        try:
            original_length = len(original)
            summary_length = len(summary)
            compression_ratio = (1 - summary_length / original_length) * 100 if original_length > 0 else 0
            
            return {
                "original_length": original_length,
                "summary_length": summary_length,
                "compression_ratio": round(compression_ratio, 2),
                "model_name": self.model_name
            }
        except Exception as e:
            logger.error(f"í†µê³„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            return {}


def main():
    """
    ê°„ë‹¨í•œ ì‚¬ìš© ì˜ˆì‹œ
    """
    print("=== ê°„ë‹¨í•œ ë‰´ìŠ¤ ìš”ì•½ í”„ë¡œê·¸ë¨ ===")
    print("ëª¨ë¸ì„ ë¡œë”©í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
    
    try:
        # ìš”ì•½ê¸° ìƒì„±
        summarizer = SimpleNewsSummarizer()
        
        # ì˜ˆì‹œ ë‰´ìŠ¤
        sample_news = """
        ì„œìš¸ì‹œëŠ” ì˜¤ëŠ˜ ìƒˆë¡œìš´ í™˜ê²½ ì •ì±…ì„ ë°œí‘œí–ˆìŠµë‹ˆë‹¤. 
        ì´ë²ˆ ì •ì±…ì€ íƒ„ì†Œ ë°°ì¶œëŸ‰ì„ 2030ë…„ê¹Œì§€ 40% ê°ì¶•í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.
        ì‹œë¯¼ë“¤ì˜ ì°¸ì—¬ê°€ ì¤‘ìš”í•œ ì´ë²ˆ ì •ì±…ì€ ë‹¤ì–‘í•œ ì¸ì„¼í‹°ë¸Œë¥¼ ì œê³µí•  ì˜ˆì •ì…ë‹ˆë‹¤.
        """
        
        print("\n=== ì˜ˆì‹œ ìš”ì•½ ===")
        print(f"ì›ë³¸: {sample_news.strip()}")
        
        summary = summarizer.summarize(sample_news)
        print(f"ìš”ì•½: {summary}")
        
        stats = summarizer.get_summary_stats(sample_news, summary)
        print(f"ì••ì¶•ë¥ : {stats.get('compression_ratio', 0)}%")
        
        print("\n=== ëŒ€í™”í˜• ëª¨ë“œ ===")
        print("ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œ: quit)")
        
        while True:
            try:
                user_input = input("\n> ")
                
                if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
                    print("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
                
                if not user_input.strip():
                    print("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    continue
                
                print("ìš”ì•½ ìƒì„± ì¤‘...")
                summary = summarizer.summarize(user_input)
                print(f"ğŸ“° ìš”ì•½: {summary}")
                
            except KeyboardInterrupt:
                print("\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            except Exception as e:
                print(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                
    except Exception as e:
        print(f"í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")


if __name__ == "__main__":
    main() 